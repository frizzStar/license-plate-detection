{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11655130,"sourceType":"datasetVersion","datasetId":7314371},{"sourceId":11655194,"sourceType":"datasetVersion","datasetId":7314411},{"sourceId":370397,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":306652,"modelId":327140}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages (run once)\n!pip install ultralytics opencv-python-headless kaggle --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T00:04:43.833531Z","iopub.execute_input":"2025-05-03T00:04:43.833738Z","iopub.status.idle":"2025-05-03T00:06:03.687907Z","shell.execute_reply.started":"2025-05-03T00:04:43.833713Z","shell.execute_reply":"2025-05-03T00:06:03.686999Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom ultralytics import YOLO\nfrom IPython.display import HTML\nfrom base64 import b64encode\n\ndef test_video_kaggle(model_path, video_path, output_path, conf_threshold=0.5):\n    # Load model (automatically uses GPU if available in Kaggle)\n    model = YOLO(model_path)\n    \n    # Initialize video capture\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Error opening video: {video_path}\")\n        return\n\n    # Get video properties\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Initialize video writer (use XVID codec if MP4V doesn't work)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n    \n    print(f\"Processing video: {total_frames} frames ({fps} FPS)\")\n    \n    frame_count = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n            \n        # Perform detection (automatically uses GPU)\n        results = model.predict(frame, conf=conf_threshold, verbose=False)\n        \n        # Plot detections\n        annotated_frame = results[0].plot()\n        \n        # Write frame\n        out.write(annotated_frame)\n        \n        # Progress update\n        frame_count += 1\n        if frame_count % 100 == 0:\n            print(f\"Processed {frame_count}/{total_frames} frames\")\n\n    # Clean up\n    cap.release()\n    out.release()\n    print(f\"Video processing complete. Output saved to: {output_path}\")\n\ndef show_video(video_path):\n    # Display processed video in notebook\n    video_file = open(video_path, \"rb\").read()\n    data_url = \"data:video/mp4;base64,\" + b64encode(video_file).decode()\n    return HTML(f\"\"\"<video width=600 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")\n\n# Kaggle paths configuration\nMODEL_PATH = '/kaggle/input/tmodel1/pytorch/default/1/best.pt'  # Upload your model first\nVIDEO_PATH = '/kaggle/input/testing-p/ptest_2.mp4'  # Upload your video\nOUTPUT_PATH = '/kaggle/working/output_3.mp4'\n\n# Run video detection\ntest_video_kaggle(MODEL_PATH, VIDEO_PATH, OUTPUT_PATH, conf_threshold=0.25)\n\n# Display processed video (might not work for large files)\nshow_video(OUTPUT_PATH)\nfrom IPython.display import FileLink\nFileLink(OUTPUT_PATH)  # Click link to download result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T00:24:42.784548Z","iopub.execute_input":"2025-05-03T00:24:42.785055Z","iopub.status.idle":"2025-05-03T00:25:36.804545Z","shell.execute_reply.started":"2025-05-03T00:24:42.785033Z","shell.execute_reply":"2025-05-03T00:25:36.803949Z"}},"outputs":[{"name":"stdout","text":"Processing video: 2123 frames (30 FPS)\nProcessed 100/2123 frames\nProcessed 200/2123 frames\nProcessed 300/2123 frames\nProcessed 400/2123 frames\nProcessed 500/2123 frames\nProcessed 600/2123 frames\nProcessed 700/2123 frames\nProcessed 800/2123 frames\nProcessed 900/2123 frames\nProcessed 1000/2123 frames\nProcessed 1100/2123 frames\nProcessed 1200/2123 frames\nProcessed 1300/2123 frames\nProcessed 1400/2123 frames\nProcessed 1500/2123 frames\nProcessed 1600/2123 frames\nProcessed 1700/2123 frames\nProcessed 1800/2123 frames\nProcessed 1900/2123 frames\nProcessed 2000/2123 frames\nProcessed 2100/2123 frames\nVideo processing complete. Output saved to: /kaggle/working/output_3.mp4\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/output_3.mp4","text/html":"<a href='/kaggle/working/output_3.mp4' target='_blank'>/kaggle/working/output_3.mp4</a><br>"},"metadata":{}}],"execution_count":9}]}